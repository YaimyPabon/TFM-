{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73abac1-2f4e-4126-9a6d-176c37b1205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VCF a FASTA\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "\n",
    "ins_vcf = \"inserciones.vcf\"\n",
    "ins_fasta = \"inserciones.fasta\"\n",
    "\n",
    "def vcf_to_fasta():\n",
    "    records = []\n",
    "    with open(ins_vcf) as vcf:\n",
    "        for line in vcf:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            cols = line.strip().split(\"\\t\")\n",
    "            if len(cols) < 5: continue\n",
    "\n",
    "            chrom, pos, _, ref, alt = cols[:5]\n",
    "            if \"<INS>\" in alt:\n",
    "                continue\n",
    "            if len(alt) > len(ref):\n",
    "                insertion_seq = alt[len(ref):]\n",
    "                seq_record = SeqRecord(\n",
    "                    Seq(insertion_seq.strip()),\n",
    "                    id=f\"{chrom}:{pos}\",\n",
    "                    description=\"\"\n",
    "                )\n",
    "                records.append(seq_record)\n",
    "\n",
    "    with open(ins_fasta, \"w\") as output_handle:\n",
    "        SeqIO.write(records, output_handle, \"fasta\")\n",
    "    print(f\"FASTA generado: {ins_fasta}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vcf_to_fasta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fcd03b-b991-4754-a829-f22586a2428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validación archivo fasta \n",
    "def validar_fasta(ruta_archivo):\n",
    "    with open(ruta_archivo) as f:\n",
    "        line_num = 0\n",
    "        seq_started = False\n",
    "        for line in f:\n",
    "            line_num += 1\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                seq_started = True\n",
    "            else:\n",
    "                if not seq_started:\n",
    "                    print(f\"Error en línea {line_num}: Secuencia sin encabezado.\")\n",
    "                    return False\n",
    "                if not line.isalpha():\n",
    "                    print(f\"Error en línea {line_num}: Secuencia contiene caracteres no alfabéticos.\")\n",
    "                    return False\n",
    "    print(\"Archivo FASTA validado correctamente.\")\n",
    "    return True\n",
    "# Llamas a la función pasando la ruta correcta\n",
    "validar_fasta(\"/home/alumno16/TFM1/inserciones.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13171e56-9e93-443c-862a-2af99735a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrado 1\n",
    "import pandas as pd\n",
    "\n",
    "cols = [\n",
    "    \"qseqid\", \"sseqid\", \"pident\", \"length\", \"mismatch\", \"gapopen\",\n",
    "    \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"resultados_inserciones_vs_exones.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=cols\n",
    ")\n",
    "\n",
    "# Filtro razonable: si pongo 200 pierdo el control positivo \n",
    "filtered = df[\n",
    "    (df[\"pident\"] >= 90) &\n",
    "    (df[\"length\"] >= 180) &\n",
    "    (df[\"evalue\"] <= 1e-5)\n",
    "]\n",
    "\n",
    "# Mejor hit por inserción (qseqid)\n",
    "best_hits = (\n",
    "    filtered\n",
    "    .sort_values([\"qseqid\", \"bitscore\", \"evalue\"], ascending=[True, False, True])\n",
    "    .drop_duplicates(\"qseqid\", keep=\"first\")\n",
    ")\n",
    "\n",
    "best_hits.to_csv(\"resultados_filtrados.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487612c-4115-4ab3-99e6-9e6b7e66dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio el tsv a csv para mejor manejo de datos\n",
    "import pandas as pd\n",
    "# Cambia el nombre por tu archivo\n",
    "input_file = 'resultados_filtrados1.tsv'\n",
    "output_file = 'resultados_procesados1.csv'\n",
    "# Nombres de columnas que mencionaste\n",
    "cols = ['qseqid', 'sseqid', 'pident', 'length', 'mismatch', 'gapopen',\n",
    "        'qstart', 'qend', 'sstart', 'send', 'evalue', 'bitscore']\n",
    "# Leer archivo TSV\n",
    "df = pd.read_csv(input_file, sep='\\t', names=cols)\n",
    "# 1) Separar qseqid en dos columnas nuevas: \"chr\" y \"pos\"\n",
    "qseq_split = df['qseqid'].str.split(':', n=1, expand=True)\n",
    "df['chr'] = qseq_split[0]\n",
    "df['pos'] = qseq_split[1]\n",
    "# 2) Separar sseqid en 4 columnas nuevas: ensg, enst, ense, resto\n",
    "# Separar por '|'\n",
    "sseq_split = df['sseqid'].str.split('|', expand=True)\n",
    "df['ensg'] = sseq_split[0]\n",
    "df['enst'] = sseq_split[1]\n",
    "df['ense'] = sseq_split[2]\n",
    "df['resto'] = sseq_split[3]\n",
    "# Opcional: eliminar las columnas originales si quieres\n",
    "df.drop(['qseqid', 'sseqid'], axis=1, inplace=True)\n",
    "# Definir orden de columnas nuevas que quieres al inicio\n",
    "cols_new = ['chr', 'pos', 'ensg', 'enst', 'ense', 'resto']\n",
    "# Columnas restantes\n",
    "cols_restantes = [col for col in df.columns if col not in cols_new]\n",
    "# Reordenar DataFrame poniendo primero las nuevas\n",
    "df = df[cols_new + cols_restantes]\n",
    "# Ordenar por 'resto' ascendente\n",
    "df = df.sort_values(by='resto')\n",
    "# Guardar como CSV (puedes cambiar sep='\\t' para TSV si prefieres)\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Archivo procesado guardado en {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6f0f3a-0473-4fbb-8735-b6713d39f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrado 2, inserciones que contengan 2 ó más exones\n",
    "import pandas as pd\n",
    "\n",
    "# Definir nombres de columnas según tu encabezado\n",
    "cols = [\n",
    "    \"chr\", \"pos\", \"ensg\", \"enst\", \"ense\", \"genID\",\n",
    "    \"pident\", \"length\", \"mismatch\", \"gapopen\",\n",
    "    \"qstart\", \"qend\", \"sstart\", \"send\",\n",
    "    \"evalue\", \"bitscore\"\n",
    "]\n",
    "\n",
    "# Cargar CSV\n",
    "df = pd.read_csv(\"resultados_procesados1.csv\", names=cols, header=0)\n",
    "\n",
    "# Agrupar por gen y posición y contar exones distintos\n",
    "conteo_exones_por_pos = (\n",
    "    df.groupby([\"ensg\", \"pos\"])[\"ense\"]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"ense\": \"n_exones_en_pos\"})\n",
    ")\n",
    "\n",
    "# Filtrar posiciones con ≥ 2 exones\n",
    "conteo_mas_de_1_exon = conteo_exones_por_pos[\n",
    "    conteo_exones_por_pos[\"n_exones_en_pos\"] >= 2\n",
    "]\n",
    "\n",
    "# Hacer merge con el DataFrame original para recuperar las demás columnas\n",
    "# Nos quedamos solo con filas que tengan esos ensg y pos\n",
    "df_filtrado = df.merge(\n",
    "    conteo_mas_de_1_exon,\n",
    "    on=[\"ensg\", \"pos\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Opcional: quitar duplicados si solo quieres una fila por posición\n",
    "df_filtrado = df_filtrado.drop_duplicates(\n",
    "    subset=[\"chr\", \"pos\", \"ensg\", \"n_exones_en_pos\"]\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(df_filtrado[[\"chr\", \"pos\", \"ensg\", \"n_exones_en_pos\", \"genID\"]])\n",
    "\n",
    "# Guardar si lo deseas\n",
    "df_filtrado.to_csv(\"conteo_exones.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
